# ğŸ“˜ Learning Guide: RAG Chatbot with MongoDB & Azure OpenAI

This guide explains the complete workflow of building a Retrieval-Augmented Generation (RAG) chatbot.  
It breaks down each section of the notebook with detailed explanations and **paper sketches** (ASCII diagrams).

---

## ğŸ”¹ Section 1: Knowledge Base

**Goal:** Convert raw text into structured documents.

- Start with long raw text documents.
- Convert each into a LangChain `Document` object:
  - `page_content` â†’ actual text
  - `metadata` â†’ labels (`source`, `doc_id`)

**Paper Sketch:**
```text
[Raw long docs]
    â”œâ”€ Doc 1: "Python is a high-level language..."
    â”œâ”€ Doc 2: "Machine learning is a subset of AI..."
    â”œâ”€ Doc 3: "Web development involves..."
    â””â”€ Doc 4: "Discord bots are applications..."

     â”‚
     â–¼

[LangChain Documents]
    â”œâ”€ Document(page_content="Python...", metadata={"source": "doc_1", "doc_id": 0})
    â”œâ”€ Document(page_content="Machine learning...", metadata={"source": "doc_2", "doc_id": 1})
    â”œâ”€ Document(page_content="Web development...", metadata={"source": "doc_3", "doc_id": 2})
    â””â”€ Document(page_content="Discord bots...", metadata={"source": "doc_4", "doc_id": 3})

---

## ğŸ”¹ Section 2: Chunking & Splitting

**Goal:** Break down long documents into smaller, overlapping chunks.

- Use `RecursiveCharacterTextSplitter` (chunk_size = 1000, overlap = 50).
- Overlap prevents losing boundary info.
- Extract `chunks_texts` for embeddings.

**Paper Sketch:**
```text
[LangChain Documents]
     â”‚
     â–¼
RecursiveCharacterTextSplitter (chunk_size=1000, overlap=50)
     â”‚
     â–¼
Chunks created:
    â”œâ”€ Chunk 1 (1000 chars)
    â”œâ”€ Chunk 2 (last 50 overlap + 950 new)
    â””â”€ Chunk 3 (and so on...)

Each chunk keeps:
    page_content = "chunk text"
    metadata = {"source": "doc_X", "doc_id": Y}
ğŸ”¹ Section 3: Embeddings
Goal: Represent chunks as vectors.

Use all-MiniLM-L6-v2 (SentenceTransformer).

Each chunk â†’ 384-dim embedding.

Collect all embeddings in doc_embeddings (matrix: num_chunks Ã— 384).

Pair embeddings back with chunk text + metadata to form documents_to_insert.

Paper Sketch:

text
Copy code
[Chunk Texts]
     â”‚
     â–¼
Embedding Model (MiniLM-L6-v2)
     â”‚
     â–¼
doc_embeddings (num_chunks Ã— 384)
     â”œâ”€ [0.12, -0.45, 0.33, ...] â† Chunk 1
     â”œâ”€ [0.05,  0.99, -0.10, ...] â† Chunk 2
     â””â”€ [0.77, -0.21,  0.14, ...] â† Chunk 3

     â”‚
     â–¼
documents_to_insert:
    â”œâ”€ {"_id": 0, "text": "Python...", "embedding": [...], "source": "doc_1"}
    â”œâ”€ {"_id": 1, "text": "Machine learning...", "embedding": [...], "source": "doc_2"}
    â””â”€ {"_id": 2, "text": "Web development...", "embedding": [...], "source": "doc_3"}
ğŸ”¹ Section 4: MongoDB Atlas Integration
Goal: Store vectors in a database and enable semantic search.

Insert documents_to_insert into MongoDB Atlas.

Create a vector index (numDimensions = 384, metric = cosine).

Run queries by embedding user input and searching with $vectorSearch.

Retrieve top-k most similar chunks.

Paper Sketch:

text
Copy code
Insert:
[documents_to_insert] â”€â”€> MongoDB Collection

Index:
Index name = vector_index
Path = embedding
numDimensions = 384
similarity = cosine

Query:
User Q = "Who created Python?"
     â”‚
     â–¼
Embed Query â†’ [384-dim vector]
     â”‚
     â–¼
$vectorSearch in MongoDB
     â”‚
     â–¼
Top-k docs returned:
    â”œâ”€ {"_id": 0, "text": "Python created by Guido...", "source": "doc_1", "score": 0.99}
    â””â”€ {"_id": 3, "text": "Python emphasizes readability...", "source": "doc_1", "score": 0.87}
ğŸ”¹ Section 5: LLM Integration & Prompt Engineering
Goal: Make the LLM answer only from retrieved context (avoid hallucination).

Configure Azure OpenAI GPT-3.5 Turbo.

Create prompts:

System prompt â†’ strict rules (only use provided context, cite sources, say â€œI donâ€™t knowâ€ if missing).

User prompt â†’ inserts {context} and {question}.

Build context from retrieved documents using build_context_from_docs().

Call Azure GPT with call_azure_chat().

rag_query() = retrieval + context + prompt + LLM â†’ answer.

Paper Sketch:

text
Copy code
User Question: "Who created Python?"
     â”‚
     â–¼
MongoDB Vector Search â†’ Top-k Docs
     â”‚
     â–¼
build_context_from_docs()
     â”‚
     â–¼
Context string:
    [source:doc_1] Python was created by Guido van Rossum in 1991.

Prompt:
SYSTEM_PROMPT = "Answer ONLY using context. Cite sources."
USER_PROMPT =
    CONTEXT:
    [source:doc_1] Python...

    QUESTION:
    Who created Python?

    ANSWER:

     â”‚
     â–¼
Azure GPT-3.5 Turbo
     â”‚
     â–¼
Answer:
"Python was created by Guido van Rossum in 1991. [source:doc_1]"
ğŸ”¹ Section 6: Full RAG Pipeline
Goal: Orchestrate the entire workflow into a single function.

retrieve_docs_for_query() â†’ embed query, run Atlas $vectorSearch, fallback if needed, normalize results.

build_rag_prompt() â†’ build context string from retrieved docs + insert into system/user templates.

call_llm_for_rag() â†’ wrapper around Azure GPT call.

run_rag_pipeline() â†’ end-to-end: retrieve â†’ prompt â†’ LLM â†’ extract sources â†’ return structured result.

Paper Sketch:

text
Copy code
[User Question]
     â”‚
     â–¼
retrieve_docs_for_query()
   (embed query â†’ Atlas vectorSearch â†’ fallback if needed)
     â”‚
     â–¼
Top-k Docs (normalized: _id, text, source, score)
     â”‚
     â–¼
build_rag_prompt()
   (assemble context string + system & user prompts)
     â”‚
     â–¼
call_llm_for_rag()
   (send prompts to Azure GPT-3.5 Turbo)
     â”‚
     â–¼
Azure GPT â†’ Answer
     â”‚
     â–¼
Extract sources [source:doc_X]
     â”‚
     â–¼
Return structured result:
{
  "question": "Who created Python?",
  "answer": "Python was created by Guido van Rossum in 1991. [source:doc_1]",
  "docs": [...],
  "sources": ["doc_1"],
  "context": "[source:doc_1] Python..."
}
âœ… Final Overview (End-to-End)
Full pipeline in one sketch:

text
Copy code
[Raw Docs] 
     â–¼
LangChain Documents
     â–¼
Chunking & Splitting
     â–¼
Embeddings (MiniLM, 384-dim)
     â–¼
MongoDB Atlas (vector index)
     â–¼
User Query â†’ Embed
     â–¼
MongoDB $vectorSearch â†’ Top-k Docs
     â–¼
Context Builder â†’ Prompt
     â–¼
Azure GPT-3.5 Turbo
     â–¼
Answer (grounded + citations)
